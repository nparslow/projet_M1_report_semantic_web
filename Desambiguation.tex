\section{Désambiguation}
\subsection{Programme}

La deuxièmme tâche que nous nous sommes donnée est la désambiguisation des mots
en contexte. Cela consiste à calculer la distance entre, d'une 
part, une phrase entrée par l'utilisateur et, d'autre part, chaque définition 
du mot à disambiguïser. Le programme va alors calculer un vector pour chaque 
couple (phrase / définition) et la définition renvoyée sera celle ayant la 
distance la plus petite.

Dans un premier temps on tagge puis lemmatise la phrase et les définitions pour 
qu'ils soient en adéquation avec nos données.

Ensuite, on peut calculer la distance entre la phrase et une définition, pour 
se faire, il y a deux étapes: la création des veteurs et le calcul de la 
distance euclidéenne entre ces vecteurs.


\subsection{création des vecteurs}

Pour chaque mot (de la phrase ou des définitions), nous récupérons ses k plus 
proches voisins. Puis nous mémorisons dans un dictionnaire chaque voisin (clef) 
ainsi que son vecteur dans la matrice (valeur). Ce dictionnaire représente le 
vecteur de notre mot.

Pour effectuer le calcul du vecteur de la phrase (ou des dictionnaires) nous 
comparons chaque vecteur-mot au vecteur-phrase. si l'un de ses voisin n'est pas 
encore voisin de la phrase, on l'ajoute. Sinon on prend le vecteur-voisin le 
plus petit entre celui du mot et celui déjà présent dans la phrase.


\subsection{calcul de la distance euclidienne}

Une fois que nous possédons le vecteur-phrase ainsi que les 
vecteurs-définition, nous calculons la distance euclidienne entre la phrase et 
chaque définition. Il ne reste plus qu'à récupérer la plus petite distance 
euclidiene pour connaître la définition prédite.


\subsection{Evaluation : RomansEval}

L'évaluation de ce programme a été faite grâce au corpus RomansEval. Il a été 
mis au point dans l'optique d'évaluer, lors d'une compétition, des 
systèmes de désambiguisation de mots sur des textes littéraires. 

Ce corpus est constitué d'environ 45000 phrases. Certains mots présents dans ce 
corpus sont ambigus. Ces mots sont regroupés dans trois fichiers HTML (un 
fichier par catégorie syntaxique : Adj, N, V) qui contiennet en plus leurs 
différents définitions. Et pour finir, ils sont aussi répertoriés dans un 
fichier de référence avec diverses informations supplémentaires telles que :

\begin{enumerate}
 \item la catégorie syntaxique du mot
 \item son lemme
 \item le numero de la phrase dans laquelle il apparait
 \item l'occurrence présente dans la phrase
 \item les différents votes des personnes qui ont fait ce corpus
 \item la définition qui eu le nombre de voix le plus élevé
 \end{enumerate}

Pour réaliser notre évaluation, nous avons mis au point un script qui, pour 
chaque fichier HTML, le lit et récupère les informations pertinentes dans un 
dictionnaires python. Ensuite le fichier de référence est lu ligne par ligne 
ce qui permet de connaître chaque occurrence, son contexte et les définitions 
liées à ce lemme.

Le corpus étant beaucoup trop important, nous n'avons pas pu nous servir de 
toutes les données qu'il contient. Pour chaque lemme nous avons analysé les 5 
premières occurrences de chaque mot pour avoir un score d'exactitude le plus 
précis possible dans le temps imparti.

Pour avoir une baseline à laquelle comparer notre désambiguisateur nous avons 
laancé, en même temps que notre calcul d'exactitude, un random qui choisit une 
définition parmi celles disponibles.

Le score obtenu est un peu différent selon la catégorie observée:

\begin{itemize}
 \item {Adjectifs:
	\begin{itemize}
	 \item Notre exactitude : 39,80 \%
	 \item Exactitude de random : 14,29 \%
	\end{itemize}
	}
 \item {Noms:
 	\begin{itemize}
	 \item Notre exactitude : 22,64 \%
	 \item Exactitude de random : 16,98 \%
	\end{itemize}
	}
 \item {Verbes:
 	\begin{itemize}
	 \item Notre exactitude : 12,94 \%
	 \item Exactitude de random : 11,76 \%
	\end{itemize}
	}
\end{itemize}

Nous avons conscience que ces scores ne sont pas le meilleurs possibles mais 
celà peut en partie s'expliquer en étudiant de plus près les définitions. En 
effet, si l'on regarde par exemple le lemme FRAIS. Il possède, dans le 
RomansEval, huit définitions différentes. Et parmi ces huit définitions 
certaines sont très proches et la différence entre elles est difficile à 
percevoir, même pour un être humain. Par exemple : `Qui est légèrement froid ou 
qui procure une sensation de froid léger.' et `Qui est empreint de froideur, 
dépourvu de cordialité.' sont deux défintions qui utilisent plusieurs mots 
identiques ou très similaires. Dans ce cas-là l'être humain comprend bien que la 
première définition désigne plutôt une sensation physique tandis que la deuxième 
désigne un sentiment resenti.


\subsection{Désambiguisation du dictionnaire}

L'analyse marche aléatoire s'est averé beaucoup plus difficile qu'imaginé,
particulièrement au point de vu de temps. Par contre il y a quelques
résultats. Tout d'abbord le nombre d'itérations pour trouver le
point stable. Pour le graphe du littré le point stable est trouvé
après d'environ 80 multiplications, ce qui est trop lent pour utiliser.
Heureusement le point ou la définition la plus probable est fixe est
de l'ordre six, comme on voit dans le table suivant:

\begin{tabular}{|l|c|c|c|c|c|}
\hline
nombe d'itérations & 3  & 4  & 5  & 6  & 12 \\
\hline
déterminer\_V\_4   & 1  & 1  & 1  & 1  & 1  \\
ferrer\_V\_3       & 14 & 14 & 4  & 14 & 14 \\
temps\_N\_32       & 6  & 2  & 2  & 2  & 2  \\
temps\_N\_9        & 6  & 2  & 2  & 2  & 2  \\
état\_N\_5         & 9  & 9  & 9  & 9  & 9  \\
quadrille\_N\_3    & 7  & 7  & 7  & 7  & 7  \\
extrémité\_N\_8    & 5  & 14 & 14 & 14 & 14 \\
entrée\_N\_3       & 7  & 3  & 7  & 7  & 7  \\
heure\_N\_3        & 11 & 11 & 11 & 11 & 11 \\
annoncer\_V\_2     & 6  & 3  & 3  & 3  & 3  \\
\hline
\end{tabular}

le table demonstre le meilleur définition pour le pos ``moment\_''
dans les définitions dans le table et comment cela se modifie avec
les itérations de la multiplication de matrice.
